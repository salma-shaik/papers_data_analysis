{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['artTitle', 'pubYear', 'pubJournal', 'artAbstract', 'artKeywords']\n",
      "325\n"
     ]
    }
   ],
   "source": [
    "### Clean web of science articles\n",
    "\n",
    "wos_ini = pd.read_excel('/Users/salma/Research/papers_data_analysis/bda_ml_wm_lr/WOS_export2020-09-26.xls')\n",
    "\n",
    "# Get only J type publications and only these fields: 'Author Full Names', 'Article Title',\n",
    "# 'Source Title', 'Abstract', 'Publication Date', 'Publication Year'\n",
    "df_req = df_all.query('`Publication Type` == \"J\"').loc[:, ['Article Title', 'Publication Year',\n",
    "                                                           'Source Title', 'Abstract', \n",
    "                                                           'Author Keywords']]\n",
    "\n",
    "# artTitle, pubYear , pubJournal, artAbstract\n",
    "df_req.rename(columns={'Article Title': 'artTitle', 'Publication Year': 'pubYear', \n",
    "                       'Source Title': 'pubJournal', 'Abstract': 'artAbstract',\n",
    "                      'Author Keywords': 'artKeywords'}, inplace=True)\n",
    "print(list(df_req))\n",
    "print(df_req.shape[0])\n",
    "df_req.to_csv('/Users/salma/Research/papers_data_analysis/bda_ml_wm_lr/db_req_fields_articles/bda_ml_wm_wos_req_s1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['artTitle', 'pubYear', 'pubJournal', 'artAbstract', 'artKeywords']\n",
      "143\n"
     ]
    }
   ],
   "source": [
    "#### Clean proquest articles\n",
    "pro_df = pd.read_excel('/Users/salma/Research/papers_data_analysis/bda_ml_wm_lr/ProQuestDocuments-2020-09-26.xls')\n",
    "\n",
    "pro_df_req = pro_df.query('documentType != \"Feature\"').loc[:, ['Title', 'pubdate', 'pubtitle', 'Abstract', 'subjectTerms', 'subjects']]\n",
    "\n",
    "pro_df_req['artKeywords'] = pro_df_req['subjectTerms'] + pro_df_req['subjects']\n",
    "\n",
    "# artTitle, pubYear , pubJournal, artAbstract\n",
    "pro_df_req.rename(columns={'Title': 'artTitle', 'pubdate': 'pubYear', 'pubtitle': 'pubJournal', 'Abstract': 'artAbstract'}, inplace=True)\n",
    "\n",
    "pro_df_req = pro_df_req.drop(['subjectTerms', 'subjects'], axis=1)\n",
    "\n",
    "print(list(pro_df_req))\n",
    "print(pro_df_req.shape[0])\n",
    "pro_df_req.to_csv('/Users/salma/Research/papers_data_analysis/bda_ml_wm_lr/db_req_fields_articles/bda_ml_wm_pq_req_s1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['artTitle', 'pubYear', 'pubJournal', 'artAbstract', 'artKeywords']\n",
      "614\n"
     ]
    }
   ],
   "source": [
    "### Clean science direct files\n",
    "os.chdir('/Users/salma/Research/papers_data_analysis/bda_ml_wm_lr/sci_dir_ini')\n",
    "\n",
    "df = []\n",
    "\n",
    "for fl in os.listdir():\n",
    "    ## Without sep ='\\t' option, it was throwing ParserError: Error tokenizing data. \n",
    "    #C error: Expected 31 fields in line 44, saw 32 (sci)_dir_6.csv\n",
    "    # data = pd.read_csv('file1.csv', error_bad_lines=False) - works but just ignores the bad lines\n",
    "    ## tried using sep='\\t', loads correctly but then each row of df was just 1 continuous string\n",
    "    # so manually removed offending line for now\n",
    "\n",
    "    if fl != '.DS_Store':\n",
    "        df.append(pd.read_csv(fl))\n",
    "\n",
    "sci_dir_df = pd.concat(df, axis=0)\n",
    "\n",
    "# Title, Journal, Year, Custom1\n",
    "sci_dir_req_df = sci_dir_df.loc[:, ['Title', 'Year', 'Journal', 'Custom1', 'Custom3']]\n",
    "\n",
    "# artTitle, pubYear, pubJournal, artAbstract\n",
    "sci_dir_req_df.rename(columns={'Title': 'artTitle', 'Year': 'pubYear', 'Journal': 'pubJournal', \n",
    "                               'Custom1': 'artAbstract', 'Custom3': 'artKeywords'}, inplace=True)\n",
    "print(list(sci_dir_req_df))\n",
    "print(sci_dir_req_df.shape[0])\n",
    "sci_dir_req_df.to_csv('/Users/salma/Research/papers_data_analysis/bda_ml_wm_lr/db_req_fields_articles/bda_ml_wm_sd_req_s1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IEEE_ab_export2020-09-26.csv\n",
      "IEEE_ti_export2020-09-26.csv\n",
      "IEEE_kw_export2020-09-26.csv\n",
      "['artTitle', 'pubYear', 'pubJournal', 'artAbstract', 'artKeywords']\n",
      "115\n"
     ]
    }
   ],
   "source": [
    "### Clean ieee xplore\n",
    "\n",
    "os.chdir('/Users/salma/Research/papers_data_analysis/bda_ml_wm_lr/ieee_ini')\n",
    "\n",
    "df = []\n",
    "\n",
    "for fl in os.listdir():\n",
    "    print(fl)\n",
    "    if fl != '.DS_Store':\n",
    "        df.append(pd.read_csv(fl))\n",
    "\n",
    "ieee_df = pd.concat(df, axis=0)\n",
    "\n",
    "ieee_df_req = ieee_df.loc[:, ['Document Title', 'Date Added To Xplore', 'Publication Title', 'Abstract', 'Author Keywords']]\n",
    "ieee_df_req.rename(columns={'Document Title': 'artTitle', 'Date Added To Xplore': 'pubYear', \n",
    "                            'Publication Title': 'pubJournal', 'Abstract': 'artAbstract',\n",
    "                            'Author Keywords': 'artKeywords'}, inplace=True)\n",
    "\n",
    "print(list(ieee_df_req))\n",
    "print(ieee_df_req.shape[0])\n",
    "\n",
    "ieee_df_req.to_csv('/Users/salma/Research/papers_data_analysis/bda_ml_wm_lr/db_req_fields_articles/bda_ml_wm_ieee_req_s1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1419\n",
      "1204\n"
     ]
    }
   ],
   "source": [
    "### Append all db files to one\n",
    "os.chdir('/Users/salma/Research/papers_data_analysis/bda_ml_wm_lr/db_req_fields_articles')\n",
    "df = []\n",
    "\n",
    "for fl in os.listdir():\n",
    "    df.append(pd.read_csv(fl))\n",
    "\n",
    "all_dbs = pd.concat(df, axis=0)\n",
    "print(all_dbs.shape[0])\n",
    "all_dbs.drop_duplicates(subset='artTitle', keep='first', inplace=True)\n",
    "print(all_dbs.shape[0])\n",
    "         \n",
    "### get ti+ab+kw combination column\n",
    "# replace nans with empty strings or .\n",
    "all_dbs.fillna('none', inplace=True)\n",
    "all_dbs['ti_ab_kws'] = all_dbs['artTitle'] + all_dbs['artAbstract'] + all_dbs['artKeywords'] \n",
    "all_dbs.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "all_dbs.to_csv('/Users/salma/Research/papers_data_analysis/bda_ml_wm_lr/bda_ml_wm_all_db_ini_articles.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter out based on g1+g2 combination matching with ti+ab+kw combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('waste', 'big data'), ('waste', 'data mining'), ('waste', 'machine learning'), ('waste', 'artificial intelligence'), ('waste', 'descriptive'), ('waste', 'predictive'), ('waste', 'prescriptive'), ('waste', 'deep learning'), ('waste', 'neural network'), ('waste', 'neural networks'), ('waste', 'data visualization'), ('solid waste', 'big data'), ('solid waste', 'data mining'), ('solid waste', 'machine learning'), ('solid waste', 'artificial intelligence'), ('solid waste', 'descriptive'), ('solid waste', 'predictive'), ('solid waste', 'prescriptive'), ('solid waste', 'deep learning'), ('solid waste', 'neural network'), ('solid waste', 'neural networks'), ('solid waste', 'data visualization'), ('liquid waste', 'big data'), ('liquid waste', 'data mining'), ('liquid waste', 'machine learning'), ('liquid waste', 'artificial intelligence'), ('liquid waste', 'descriptive'), ('liquid waste', 'predictive'), ('liquid waste', 'prescriptive'), ('liquid waste', 'deep learning'), ('liquid waste', 'neural network'), ('liquid waste', 'neural networks'), ('liquid waste', 'data visualization'), ('waste water', 'big data'), ('waste water', 'data mining'), ('waste water', 'machine learning'), ('waste water', 'artificial intelligence'), ('waste water', 'descriptive'), ('waste water', 'predictive'), ('waste water', 'prescriptive'), ('waste water', 'deep learning'), ('waste water', 'neural network'), ('waste water', 'neural networks'), ('waste water', 'data visualization'), ('e-waste', 'big data'), ('e-waste', 'data mining'), ('e-waste', 'machine learning'), ('e-waste', 'artificial intelligence'), ('e-waste', 'descriptive'), ('e-waste', 'predictive'), ('e-waste', 'prescriptive'), ('e-waste', 'deep learning'), ('e-waste', 'neural network'), ('e-waste', 'neural networks'), ('e-waste', 'data visualization'), ('recyclable waste', 'big data'), ('recyclable waste', 'data mining'), ('recyclable waste', 'machine learning'), ('recyclable waste', 'artificial intelligence'), ('recyclable waste', 'descriptive'), ('recyclable waste', 'predictive'), ('recyclable waste', 'prescriptive'), ('recyclable waste', 'deep learning'), ('recyclable waste', 'neural network'), ('recyclable waste', 'neural networks'), ('recyclable waste', 'data visualization'), ('organic waste', 'big data'), ('organic waste', 'data mining'), ('organic waste', 'machine learning'), ('organic waste', 'artificial intelligence'), ('organic waste', 'descriptive'), ('organic waste', 'predictive'), ('organic waste', 'prescriptive'), ('organic waste', 'deep learning'), ('organic waste', 'neural network'), ('organic waste', 'neural networks'), ('organic waste', 'data visualization'), ('food waste', 'big data'), ('food waste', 'data mining'), ('food waste', 'machine learning'), ('food waste', 'artificial intelligence'), ('food waste', 'descriptive'), ('food waste', 'predictive'), ('food waste', 'prescriptive'), ('food waste', 'deep learning'), ('food waste', 'neural network'), ('food waste', 'neural networks'), ('food waste', 'data visualization')]\n"
     ]
    }
   ],
   "source": [
    "### get g1+g2 combinations list\n",
    "import itertools as it\n",
    "\n",
    "group1 = [\"waste\" , \"solid waste\" , \"liquid waste\" , \"waste water\" , \"e-waste\" , \n",
    "          \"recyclable waste\" , \"organic waste\" , \"food waste\"]\n",
    "group2 = [\"big data\" , \"data mining\" , \"machine learning\" , \"artificial intelligence\" , \n",
    "          \"descriptive\" , \"predictive\" , \"prescriptive\", \"deep learning\" , \"neural network\",\n",
    "          \"neural networks\", \"data visualization\"]\n",
    "\n",
    "comb_group = list(it.product(group1, group2))\n",
    "print(comb_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204\n",
      "1204\n",
      "651\n",
      "553\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_ti_ab_kw_comb(val):\n",
    "    count = 0\n",
    "    for item in comb_group:\n",
    "        if ((item[0].lower() in val.lower()) and (item[1].lower() in val.lower())):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "all_dbs_df = pd.read_csv('/Users/salma/Research/papers_data_analysis/bda_ml_wm_lr/bda_ml_wm_all_db_ini_articles.csv')\n",
    "print(all_dbs_df.shape[0])\n",
    "all_dbs_df['req_paper'] = all_dbs_df['ti_ab_kws'].map(check_ti_ab_kw_comb)\n",
    "print(all_dbs_df.shape[0])\n",
    "all_dbs_df.to_csv('/Users/salma/Research/papers_data_analysis/bda_ml_wm_lr/bda_ml_wm_all_db_tiabkw_true_false_articles.csv', index=False)\n",
    "all_dbs_df.query('req_paper == True').to_csv('/Users/salma/Research/papers_data_analysis/bda_ml_wm_lr/bda_ml_wm_all_db_tiabkw_true_articles.csv', index=False)\n",
    "print(all_dbs_df.query('req_paper == True').shape[0])\n",
    "all_dbs_df.query('req_paper == False').to_csv('/Users/salma/Research/papers_data_analysis/bda_ml_wm_lr/bda_ml_wm_all_db_tiabkw_false_articles.csv', index=False)\n",
    "print(all_dbs_df.query('req_paper == False').shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "papers_data_analysis",
   "language": "python",
   "name": "papers_data_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
